{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GGdDzNp-gEg"
   },
   "source": [
    "### In the lecture you have been introduced to VGG16. For this problem your task is to implement a VGG like CNN architecture for classification on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BQs8RyYL9nUc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZ1AZfUD_HZ9"
   },
   "source": [
    "### 1. Load the dataset (0.5 point)\n",
    "To load the dataset, you can use the inbuilt dataloader for CIFAR10 provided in the torchvision package. Load both test set and trainset separately. Define the transformations you might need to load the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOSZHQRT9nUr",
    "outputId": "68e7792f-9fa3-4981-c21d-8d5d3b629260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
    "                                                    download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                                    shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
    "                                                    download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                                    shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGpxcaoc_te7"
   },
   "source": [
    "### Create the model architecture (1.0 point)\n",
    "Implement the class below such that the final architecture follows the same pattern of layers as VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BeCGIwT99nUs"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_channels = 3, n_classes= 10):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        layers = [64, 64, \"maxpool\", 128, 128, \"maxpool\", 256, 256, 256, \"maxpool\", 512, 512, 512, \"maxpool\", 512, 512, 512, \"maxpool\"]\n",
    "        feature_extracters = []\n",
    "\n",
    "        for out_channels in layers:\n",
    "          if out_channels == \"maxpool\":\n",
    "            feature_extracters.append(nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n",
    "\n",
    "          else:\n",
    "            feature_extracters.append(nn.Conv2d(in_channels=input_channels, out_channels=out_channels, \n",
    "                                              kernel_size=(3,3), padding=(1,1), stride=(1,1)))\n",
    "            feature_extracters.append(nn.BatchNorm2d(out_channels))\n",
    "            feature_extracters.append(nn.ReLU())\n",
    "            input_channels = out_channels\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*feature_extracters)\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, n_classes),\n",
    "        )\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out = out.view(-1, 512*1*1)\n",
    "        out = self.fc_layers(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = Net(input_channels=3, n_classes = 10).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbNC9ujQAJY6"
   },
   "source": [
    "### Loss function and optimizer (0.5 point)\n",
    "Define the loss function and optimizer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s5bALqHB9nUt"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWmCHNJSAUe1"
   },
   "source": [
    "### Train the model (1.0 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pF7eNJ389nUt",
    "outputId": "5ecb8062-03cf-411f-8435-3ba72f70e29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss: 1.9749 Acc: 0.1996\n",
      "1 Loss: 1.5684 Acc: 0.3613\n",
      "2 Loss: 1.3050 Acc: 0.5066\n",
      "3 Loss: 1.0633 Acc: 0.6152\n",
      "4 Loss: 0.8985 Acc: 0.6894\n",
      "5 Loss: 0.7603 Acc: 0.7479\n",
      "6 Loss: 0.6662 Acc: 0.7834\n",
      "7 Loss: 0.5805 Acc: 0.8146\n",
      "8 Loss: 0.4999 Acc: 0.8422\n",
      "9 Loss: 0.4488 Acc: 0.8593\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for epoch in range(epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # statistics\n",
    "      running_loss += loss.item() * inputs.size(0)\n",
    "      running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(trainloader.dataset)\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
    "\n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLlqZjZiA5nf"
   },
   "source": [
    "Code below generates the class wise accuracy of the model. You can use the results from the code below to decide the values of hyperparametrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ughmKpRj9nUu",
    "outputId": "3cf6b111-e3d6-4057-b637-dec8a8f4eaa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 84 %\n",
      "Accuracy of   car : 84 %\n",
      "Accuracy of  bird : 73 %\n",
      "Accuracy of   cat : 57 %\n",
      "Accuracy of  deer : 76 %\n",
      "Accuracy of   dog : 85 %\n",
      "Accuracy of  frog : 80 %\n",
      "Accuracy of horse : 74 %\n",
      "Accuracy of  ship : 96 %\n",
      "Accuracy of truck : 79 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ei4AsQ6_-TXW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_intro_shkh00001_mash00001.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
